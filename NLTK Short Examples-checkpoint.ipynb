{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abdb3895",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc9bca8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The goal of this course is to provide advanced training in data science, encompassing current theory and application, to real-world data analytics problems. This course builds on the fundamentals established in CSCI 3360 Data Science I, exploring advanced topics such as nonlinear dimensionality reduction, semi-supervised learning, graph algorithms, and deep learning.\n"
     ]
    }
   ],
   "source": [
    "# A \n",
    "testString =  \"The goal of this course is to provide advanced training \" + \\\n",
    "                \"in data science, encompassing current theory and \" + \\\n",
    "                \"application, to real-world data analytics problems. \" + \\\n",
    "                \"This course builds on the fundamentals established \" + \\\n",
    "                \"in CSCI 3360 Data Science I, exploring advanced topics \" + \\\n",
    "                \"such as nonlinear dimensionality reduction, semi-supervised \" + \\\n",
    "                \"learning, graph algorithms, and deep learning.\"\n",
    "print(testString)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a829d4",
   "metadata": {},
   "source": [
    "### Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f65d4f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T\n",
      "h\n",
      "e\n",
      " \n",
      "g\n",
      "o\n",
      "a\n",
      "l\n",
      " \n",
      "o\n",
      "f\n",
      " \n",
      "t\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "r\n",
      "s\n",
      "e\n",
      " \n",
      "i\n",
      "s\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "v\n",
      "i\n",
      "d\n",
      "e\n",
      " \n",
      "a\n",
      "d\n",
      "v\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "r\n",
      "a\n",
      "i\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "s\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      ",\n",
      " \n",
      "e\n",
      "n\n",
      "c\n",
      "o\n",
      "m\n",
      "p\n",
      "a\n",
      "s\n",
      "s\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "c\n",
      "u\n",
      "r\n",
      "r\n",
      "e\n",
      "n\n",
      "t\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      "o\n",
      "r\n",
      "y\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "a\n",
      "p\n",
      "p\n",
      "l\n",
      "i\n",
      "c\n",
      "a\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "t\n",
      "o\n",
      " \n",
      "r\n",
      "e\n",
      "a\n",
      "l\n",
      "-\n",
      "w\n",
      "o\n",
      "r\n",
      "l\n",
      "d\n",
      " \n",
      "d\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "a\n",
      "n\n",
      "a\n",
      "l\n",
      "y\n",
      "t\n",
      "i\n",
      "c\n",
      "s\n",
      " \n",
      "p\n",
      "r\n",
      "o\n",
      "b\n",
      "l\n",
      "e\n",
      "m\n",
      "s\n",
      ".\n",
      " \n",
      "T\n",
      "h\n",
      "i\n",
      "s\n",
      " \n",
      "c\n",
      "o\n",
      "u\n",
      "r\n",
      "s\n",
      "e\n",
      " \n",
      "b\n",
      "u\n",
      "i\n",
      "l\n",
      "d\n",
      "s\n",
      " \n",
      "o\n",
      "n\n",
      " \n",
      "t\n",
      "h\n",
      "e\n",
      " \n",
      "f\n",
      "u\n",
      "n\n",
      "d\n",
      "a\n",
      "m\n",
      "e\n",
      "n\n",
      "t\n",
      "a\n",
      "l\n",
      "s\n",
      " \n",
      "e\n",
      "s\n",
      "t\n",
      "a\n",
      "b\n",
      "l\n",
      "i\n",
      "s\n",
      "h\n",
      "e\n",
      "d\n",
      " \n",
      "i\n",
      "n\n",
      " \n",
      "C\n",
      "S\n",
      "C\n",
      "I\n",
      " \n",
      "3\n",
      "3\n",
      "6\n",
      "0\n",
      " \n",
      "D\n",
      "a\n",
      "t\n",
      "a\n",
      " \n",
      "S\n",
      "c\n",
      "i\n",
      "e\n",
      "n\n",
      "c\n",
      "e\n",
      " \n",
      "I\n",
      ",\n",
      " \n",
      "e\n",
      "x\n",
      "p\n",
      "l\n",
      "o\n",
      "r\n",
      "i\n",
      "n\n",
      "g\n",
      " \n",
      "a\n",
      "d\n",
      "v\n",
      "a\n",
      "n\n",
      "c\n",
      "e\n",
      "d\n",
      " \n",
      "t\n",
      "o\n",
      "p\n",
      "i\n",
      "c\n",
      "s\n",
      " \n",
      "s\n",
      "u\n",
      "c\n",
      "h\n",
      " \n",
      "a\n",
      "s\n",
      " \n",
      "n\n",
      "o\n",
      "n\n",
      "l\n",
      "i\n",
      "n\n",
      "e\n",
      "a\n",
      "r\n",
      " \n",
      "d\n",
      "i\n",
      "m\n",
      "e\n",
      "n\n",
      "s\n",
      "i\n",
      "o\n",
      "n\n",
      "a\n",
      "l\n",
      "i\n",
      "t\n",
      "y\n",
      " \n",
      "r\n",
      "e\n",
      "d\n",
      "u\n",
      "c\n",
      "t\n",
      "i\n",
      "o\n",
      "n\n",
      ",\n",
      " \n",
      "s\n",
      "e\n",
      "m\n",
      "i\n",
      "-\n",
      "s\n",
      "u\n",
      "p\n",
      "e\n",
      "r\n",
      "v\n",
      "i\n",
      "s\n",
      "e\n",
      "d\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ",\n",
      " \n",
      "g\n",
      "r\n",
      "a\n",
      "p\n",
      "h\n",
      " \n",
      "a\n",
      "l\n",
      "g\n",
      "o\n",
      "r\n",
      "i\n",
      "t\n",
      "h\n",
      "m\n",
      "s\n",
      ",\n",
      " \n",
      "a\n",
      "n\n",
      "d\n",
      " \n",
      "d\n",
      "e\n",
      "e\n",
      "p\n",
      " \n",
      "l\n",
      "e\n",
      "a\n",
      "r\n",
      "n\n",
      "i\n",
      "n\n",
      "g\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# NLTK has a quick method for creating a list of words in a string when normal list comprehensions are not effective\n",
    "for i in testString:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5787c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The\n",
      "goal\n",
      "of\n",
      "this\n",
      "course\n",
      "is\n",
      "to\n",
      "provide\n",
      "advanced\n",
      "training\n",
      "in\n",
      "data\n",
      "science\n",
      ",\n",
      "encompassing\n",
      "current\n",
      "theory\n",
      "and\n",
      "application\n",
      ",\n",
      "to\n",
      "real-world\n",
      "data\n",
      "analytics\n",
      "problems\n",
      ".\n",
      "This\n",
      "course\n",
      "builds\n",
      "on\n",
      "the\n",
      "fundamentals\n",
      "established\n",
      "in\n",
      "CSCI\n",
      "3360\n",
      "Data\n",
      "Science\n",
      "I\n",
      ",\n",
      "exploring\n",
      "advanced\n",
      "topics\n",
      "such\n",
      "as\n",
      "nonlinear\n",
      "dimensionality\n",
      "reduction\n",
      ",\n",
      "semi-supervised\n",
      "learning\n",
      ",\n",
      "graph\n",
      "algorithms\n",
      ",\n",
      "and\n",
      "deep\n",
      "learning\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(testString)\n",
    "for word in words:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a1bf9ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e515a70",
   "metadata": {},
   "source": [
    "### Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee56c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# There is an corpus of stopwords included in the NLTK library\n",
    "from nltk.corpus import stopwords\n",
    "stpWords = stopwords.words('english')\n",
    "print(stpWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "841a2c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a quick list to string method to view results\n",
    "def toString(words):\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37019aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant Words:  The goal course provide advanced training data science , encompassing current theory application , real-world data analytics problems . This course builds fundamentals established CSCI 3360 Data Science I , exploring advanced topics nonlinear dimensionality reduction , semi-supervised learning , graph algorithms , deep learning .\n",
      "\n",
      "Irrelevant Words:  of this is to in and to on the in such as and\n"
     ]
    }
   ],
   "source": [
    "# We can use a simple list comprehension to remove any instances of stopwords from our list of tokens\n",
    "relevantWords = []\n",
    "removedWords = []\n",
    "for word in words:\n",
    "    if word in stpWords:\n",
    "        removedWords.append(word)\n",
    "    if word not in stpWords:\n",
    "        relevantWords.append(word)\n",
    "print(\"Relevant Words: \", toString(relevantWords))\n",
    "print()\n",
    "print(\"Irrelevant Words: \", toString(removedWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ccfcb843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can define a method with this technique for faster testing\n",
    "def removeStopWords(words, stop_words):\n",
    "    cleaned = []\n",
    "    for word in words:\n",
    "        if word.lower() not in stop_words:\n",
    "            cleaned.append(word.lower()) # Lowercase output\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e7439d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The goal of this course is to provide advanced training in data science encompassing current theory and application to real world data analytics problems This course builds on the fundamentals established in CSCI 3360 Data Science I exploring advanced topics such as nonlinear dimensionality reduction semi supervised learning graph algorithms and deep learning\n"
     ]
    }
   ],
   "source": [
    "# There is still some unnecessary punctuation we can remove\n",
    "# We can use the regex tokenizer for more slightly more advanced processing\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\") #Idk what this token is I should probably figure it out\n",
    "words = tokenizer.tokenize(testString)\n",
    "print(toString(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be533a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The goal of this course is to provide advanced training in data science encompassing current theory and application to real world data analytics problems This course builds on the fundamentals established in CSCI 3360 Data Science I exploring advanced topics such as nonlinear dimensionality reduction semi supervised learning graph algorithms and deep learning\n"
     ]
    }
   ],
   "source": [
    "# We can use the method defined earlier to clean further\n",
    "wordsRelevant = removeStopWords(words, stpWords)\n",
    "print(toString(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10a6d739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goal cours provid advanc train data scienc encompass current theori applic real world data analyt problem cours build fundament establish csci 3360 data scienc explor advanc topic nonlinear dimension reduct semi supervis learn graph algorithm deep learn\n"
     ]
    }
   ],
   "source": [
    "# In order to reduce variation in words we can make use of a simplistic stemming technique\n",
    "# The porter stemmer is common\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "wordsStemmed = [stemmer.stem(word) for word in wordsRelevant]\n",
    "print(toString(wordsStemmed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2311ec89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('The', 'DET'), ('goal', 'NOUN'), ('of', 'ADP'), ('this', 'DET'), ('course', 'NOUN'), ('is', 'VERB'), ('to', 'PRT'), ('provide', 'VERB'), ('advanced', 'ADJ'), ('training', 'NOUN'), ('in', 'ADP'), ('data', 'NOUN'), ('science', 'NOUN'), ('encompassing', 'VERB'), ('current', 'ADJ'), ('theory', 'NOUN'), ('and', 'CONJ'), ('application', 'NOUN'), ('to', 'PRT'), ('real', 'ADJ'), ('world', 'NOUN'), ('data', 'NOUN'), ('analytics', 'NOUN'), ('problems', 'NOUN'), ('This', 'DET'), ('course', 'NOUN'), ('builds', 'VERB'), ('on', 'ADP'), ('the', 'DET'), ('fundamentals', 'NOUN'), ('established', 'VERB'), ('in', 'ADP'), ('CSCI', 'NOUN'), ('3360', 'NUM'), ('Data', 'NOUN'), ('Science', 'NOUN'), ('I', 'PRON'), ('exploring', 'VERB'), ('advanced', 'ADJ'), ('topics', 'NOUN'), ('such', 'ADJ'), ('as', 'ADP'), ('nonlinear', 'ADJ'), ('dimensionality', 'NOUN'), ('reduction', 'NOUN'), ('semi', 'NOUN'), ('supervised', 'VERB'), ('learning', 'VERB'), ('graph', 'NOUN'), ('algorithms', 'NOUN'), ('and', 'CONJ'), ('deep', 'ADJ'), ('learning', 'NOUN')]\n",
      "\n",
      "Output type:  <class 'list'> <class 'tuple'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can get a better representation of the distilled words using NLTK's built in word lemmatizer\n",
    "# In general, it helps to tag the part of speech before lemmatizing\n",
    "wordsPOS_test = nltk.pos_tag(words, tagset='universal') # universal tagset\n",
    "print(wordsPOS_test)\n",
    "print()\n",
    "print(\"Output type: \", type(wordsPOS), type(wordsPOS[0]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "52721e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('goal', 'NOUN'), ('course', 'NOUN'), ('provide', 'VERB'), ('advanced', 'ADJ'), ('training', 'NOUN'), ('data', 'NOUN'), ('science', 'NOUN'), ('encompassing', 'VERB'), ('current', 'ADJ'), ('theory', 'NOUN'), ('application', 'NOUN'), ('real', 'ADJ'), ('world', 'NOUN'), ('data', 'NOUN'), ('analytics', 'NOUN'), ('problems', 'NOUN'), ('course', 'NOUN'), ('builds', 'VERB'), ('fundamentals', 'NOUN'), ('established', 'VERB'), ('csci', 'ADJ'), ('3360', 'NUM'), ('data', 'NOUN'), ('science', 'NOUN'), ('exploring', 'VERB'), ('advanced', 'ADJ'), ('topics', 'NOUN'), ('nonlinear', 'ADJ'), ('dimensionality', 'NOUN'), ('reduction', 'NOUN'), ('semi', 'NOUN'), ('supervised', 'VERB'), ('learning', 'VERB'), ('graph', 'NOUN'), ('algorithms', 'ADV'), ('deep', 'ADJ'), ('learning', 'NOUN')]\n",
      "\n",
      "Output type:  <class 'list'> <class 'tuple'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can get a better representation of the distilled words using NLTK's built in word lemmatizer\n",
    "# In general, it helps to tag the part of speech before lemmatizing\n",
    "wordsPOS = nltk.pos_tag(wordsRelevant, tagset='universal') # universal tagset\n",
    "print(wordsPOS)\n",
    "print()\n",
    "print(\"Output type: \", type(wordsPOS), type(wordsPOS[0]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "21b85064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('They', 'PRON'),\n",
       " ('refuse', 'VERB'),\n",
       " ('to', 'PRT'),\n",
       " ('permit', 'VERB'),\n",
       " ('us', 'PRON'),\n",
       " ('to', 'PRT'),\n",
       " ('obtain', 'VERB'),\n",
       " ('the', 'DET'),\n",
       " ('refuse', 'NOUN'),\n",
       " ('permit', 'NOUN')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another quick example from the NLTK Book\n",
    "text = word_tokenize(\"They refuse to permit us to obtain the refuse permit\")\n",
    "nltk.pos_tag(text, tagset='universal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9df66fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('goal', 'n'),\n",
       " ('course', 'n'),\n",
       " ('provide', 'v'),\n",
       " ('advanced', 'a'),\n",
       " ('training', 'n'),\n",
       " ('data', 'n'),\n",
       " ('science', 'n'),\n",
       " ('encompassing', 'v'),\n",
       " ('current', 'a'),\n",
       " ('theory', 'n'),\n",
       " ('application', 'n'),\n",
       " ('real', 'a'),\n",
       " ('world', 'n'),\n",
       " ('data', 'n'),\n",
       " ('analytics', 'n'),\n",
       " ('problems', 'n'),\n",
       " ('course', 'n'),\n",
       " ('builds', 'v'),\n",
       " ('fundamentals', 'n'),\n",
       " ('established', 'v'),\n",
       " ('csci', 'a'),\n",
       " ('3360', 'n'),\n",
       " ('data', 'n'),\n",
       " ('science', 'n'),\n",
       " ('exploring', 'v'),\n",
       " ('advanced', 'a'),\n",
       " ('topics', 'n'),\n",
       " ('nonlinear', 'a'),\n",
       " ('dimensionality', 'n'),\n",
       " ('reduction', 'n'),\n",
       " ('semi', 'n'),\n",
       " ('supervised', 'v'),\n",
       " ('learning', 'v'),\n",
       " ('graph', 'n'),\n",
       " ('algorithms', 'a'),\n",
       " ('deep', 'a'),\n",
       " ('learning', 'n')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These pos tags are useful, but must be converted to acceptable\n",
    "# lemmatizer parameters.\n",
    "# We can define a method to do this for us\n",
    "def pos_for_lem(wordsPOS):\n",
    "    newTags = []\n",
    "    for tup in wordsPOS:\n",
    "        converted = tup[1][0].lower()\n",
    "        newTup = (tup[0], converted)\n",
    "        newTags.append(newTup)\n",
    "    return newTags\n",
    "pos_for_lem(wordsPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9043184f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('goal', 'NOUN'), ('course', 'NOUN'), ('provide', 'VERB'), ('advanced', 'ADJ'), ('training', 'NOUN'), ('data', 'NOUN'), ('science', 'NOUN'), ('encompassing', 'VERB'), ('current', 'ADJ'), ('theory', 'NOUN'), ('application', 'NOUN'), ('real', 'ADJ'), ('world', 'NOUN'), ('data', 'NOUN'), ('analytics', 'NOUN'), ('problems', 'NOUN'), ('course', 'NOUN'), ('builds', 'VERB'), ('fundamentals', 'NOUN'), ('established', 'VERB'), ('csci', 'ADJ'), ('3360', 'NUM'), ('data', 'NOUN'), ('science', 'NOUN'), ('exploring', 'VERB'), ('advanced', 'ADJ'), ('topics', 'NOUN'), ('nonlinear', 'ADJ'), ('dimensionality', 'NOUN'), ('reduction', 'NOUN'), ('semi', 'NOUN'), ('supervised', 'VERB'), ('learning', 'VERB'), ('graph', 'NOUN'), ('algorithms', 'ADV'), ('deep', 'ADJ'), ('learning', 'NOUN')]\n",
      "\n",
      "goal course provide advanced training data science encompass current theory application real world data analytics problem course build fundamental establish csci 3360 data science explore advanced topic nonlinear dimensionality reduction semi supervise learn graph algorithms deep learning\n"
     ]
    }
   ],
   "source": [
    "# We using these tags to parameterize a lemmatizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "# We convert the tags using our predefined method\n",
    "wordsPOS_LEM = pos_for_lem(wordsPOS)\n",
    "print(wordsPOS)\n",
    "wordsLemm = [lemm.lemmatize(word, pos) for word, pos in wordsPOS_LEM]\n",
    "#wordsLemm = [lemm.lemmatize(word) for word in words]\n",
    "print()\n",
    "print(toString(wordsLemm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6613d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The goal of this course is to provide advanced training in data science encompassing current theory and application to real world data analytics problems This course builds on the fundamentals established in CSCI 3360 Data Science I exploring advanced topics such as nonlinear dimensionality reduction semi supervised learning graph algorithms and deep learning\n"
     ]
    }
   ],
   "source": [
    "print(toString(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "87be9296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "print(lemm.lemmatize('running', 'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f531e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49669f47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8ad65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d02510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d791f73a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
