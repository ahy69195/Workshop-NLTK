{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f610b2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/albertyou/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/albertyou/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/albertyou/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import string \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "nltk.download('brown')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9083e3",
   "metadata": {},
   "source": [
    "# NLTK Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6af1dbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text to be normalized\n",
    "text = \"Hello, my name is Bob, and I have many cats and dogs.\"\n",
    "tokenizer = nltk.tokenize.TreebankWordTokenizer()\n",
    "# Tokenizes the text, splits up words, punctuation, etc. into a list\n",
    "tokens = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa55f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello , my name is bob , and i have mani cat and dog .'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stems the various tokens\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\" \".join(stemmer.stem(token) for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ed6b3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello , my name is Bob , and I have many cat and dog .'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizes the various tokens\n",
    "stemmer = nltk.stem.WordNetLemmatizer()\n",
    "\" \".join(stemmer.lemmatize(token) for token in tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72b82bd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello , my name is bob , and i have many cat and dog .'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can even make it lower case for futher normalization\n",
    "stemmer = nltk.stem.WordNetLemmatizer()\n",
    "\" \".join(stemmer.lemmatize(token.lower()) for token in tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dff509",
   "metadata": {},
   "source": [
    "# Brown Corpus Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e1628f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID\tFile\tGenre\tDescription\n",
    "# A16\tca16\tnews\tChicago Tribune: Society Reportage\n",
    "# B02\tcb02\teditorial\tChristian Science Monitor: Editorials\n",
    "# C17\tcc17\treviews\tTime Magazine: Reviews\n",
    "# D12\tcd12\treligion\tUnderwood: Probing the Ethics of Realtors\n",
    "# E36\tce36\thobbies\tNorling: Renting a Car in Europe\n",
    "# F25\tcf25\tlore\tBoroff: Jewish Teenage Culture\n",
    "# G22\tcg22\tbelles_lettres\tReiner: Coping with Runaway Technology\n",
    "# H15\tch15\tgovernment\tUS Office of Civil and Defence Mobilization: The Family Fallout Shelter\n",
    "# J17\tcj19\tlearned\tMosteller: Probability with Statistical Applications\n",
    "# K04\tck04\tfiction\tW.E.B. Du Bois: Worlds of Color\n",
    "# L13\tcl13\tmystery\tHitchens: Footsteps in the Night\n",
    "# M01\tcm01\tscience_fiction\tHeinlein: Stranger in a Strange Land\n",
    "# N14\tcn15\tadventure\tField: Rattlesnake Ridgez\n",
    "# P12\tcp12\tromance\tCallaghan: A Passion in Rome\n",
    "# R06\tcr06\thumor\tThurber: The Future, If Any, of Comedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6c4fb02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54a66929",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2641c251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Thirty-three', 'Scotty', 'did', 'not', 'go', 'back', ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories = 'fiction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c740b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.words(categories = 'news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "678a23d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor of order 2 based on sentences\n",
    "brown.sents(categories = 'news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3bc236eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essentially, a numpy array of the brown.words corpus\n",
    "wordArray = np.array(brown.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61d1b47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.str_'>\n"
     ]
    }
   ],
   "source": [
    "print(type(wordArray))\n",
    "print(type(wordArray[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "339e976f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161192\n",
      "['The' 'Fulton' 'County' ... 'was' 'stupefying' '.']\n",
      "Fulton\n",
      "['Fulton' 'County' 'Grand' 'Jury']\n"
     ]
    }
   ],
   "source": [
    "# There are 1,161,192 words\n",
    "count = 0\n",
    "for i in wordArray:\n",
    "    count += 1\n",
    "print(count)\n",
    "# Slicing and indexing \n",
    "print(wordArray)\n",
    "print(wordArray[1])\n",
    "print(wordArray[1:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7683e3ee",
   "metadata": {},
   "source": [
    "# Conditional Frequency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62acebd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who: 268 what: 95 when: 169 where: 59 why: 14 how: 42 "
     ]
    }
   ],
   "source": [
    "# Through nltk, you can get the categories of the brown corpus\n",
    "news_text = brown.words(categories='news')\n",
    "\n",
    "# This shows the frequency of the Modals words in the news category\n",
    "fdist = nltk.FreqDist(w.lower() for w in news_text)\n",
    "modals = ['who', 'what', 'when', 'where', 'why', 'how']\n",
    "for m in modals:\n",
    "    print(m + ':', fdist[m], end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "718cfbfd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  who  what  when where   why   how \n",
      "           news   268    95   169    59    14    42 \n",
      "       religion   102    86    68    21    20    28 \n",
      "        hobbies   104   108   164    77    17    72 \n",
      "science_fiction    13    41    28    15     8    16 \n",
      "        romance    95   171   163    58    62    77 \n",
      "          humor    49    46    62    16    13    25 \n"
     ]
    }
   ],
   "source": [
    "# Conditional frequency distribution in relation to various genres and words\n",
    "cfd = nltk.ConditionalFreqDist(\n",
    "    (genre, word.lower())\n",
    "    for genre in brown.categories()\n",
    "    for word in brown.words(categories=genre))\n",
    "genres = ['news', 'religion', 'hobbies', 'science_fiction', 'romance', 'humor']\n",
    "modals = ['who', 'what', 'when', 'where', 'why', 'how']\n",
    "\n",
    "# Shows the data in a nice tabulated format\n",
    "cfd.tabulate(conditions=genres, samples=modals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21bd2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a wordlist of lowercase and stop words from original wordArray\n",
    "wordsList = []\n",
    "for word in wordArray:\n",
    "    if word.lower() not in stopwords.words('english'):\n",
    "        wordsList.append(word.lower())\n",
    "wordsList = np.array(wordsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "075f875d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "686163\n",
      "['fulton' 'county' 'grand' 'jury' 'said']\n"
     ]
    }
   ],
   "source": [
    "# As you can see here\n",
    "print(type(wordsList))\n",
    "print(len(wordsList))\n",
    "print(wordsList[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4b3db99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                fulton county  grand   jury   said \n",
      "      adventure      0      3      1      5    288 \n",
      " belles_lettres      2      8      5      5    161 \n",
      "      editorial      0     31      2      0     52 \n",
      "        fiction      0      4      1      0    194 \n",
      "     government      0      1      2      0     18 \n",
      "        hobbies      0      8      4      0     11 \n",
      "          humor      0      1      2      0     88 \n",
      "        learned      1     18      5      3     35 \n",
      "           lore      0      8      1      4     89 \n",
      "        mystery      0      6      0      1    204 \n",
      "           news     14     61     19     46    406 \n",
      "       religion      0      0      0      0     27 \n",
      "        reviews      0      5      5      1     12 \n",
      "        romance      0      1      1      2    331 \n",
      "science_fiction      0      0      0      0     45 \n"
     ]
    }
   ],
   "source": [
    "cfd.tabulate(conditions=categories, samples=wordsList[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ba7dc7",
   "metadata": {},
   "source": [
    "# Counting Words by Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83764589",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_word = [(genre, word.lower()) \n",
    "              for genre in ['news', 'romance']\n",
    "                  for word in brown.words(categories=genre)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a5998ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('news', 'the')\n",
      "with stopwords 170576\n",
      "after no stopwords 103897\n"
     ]
    }
   ],
   "source": [
    "print(genre_word[0])\n",
    "print(\"with stopwords\", len(genre_word))\n",
    "\n",
    "genre_wordTemp = []\n",
    "for i in range(len(genre_word)):\n",
    "    if genre_word[i][1] not in stopwords.words('english'):\n",
    "            genre_wordTemp.append(genre_word[i])\n",
    "\n",
    "genre_word = genre_wordTemp\n",
    "\n",
    "print(\"after no stopwords\", len(genre_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05314083",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['news', 'romance']\n",
      "<FreqDist with 12967 samples and 63739 outcomes>\n",
      "<FreqDist with 7737 samples and 40158 outcomes>\n",
      "\n",
      "NEWS (top 20)): \n",
      "[(',', 5188), ('.', 4030), ('``', 732), (\"''\", 702), ('said', 406), (';', 314), ('--', 300), ('mrs.', 253), ('would', 246), ('new', 241), ('one', 213), ('last', 177), ('two', 174), (')', 171), ('mr.', 170), ('(', 168), ('first', 158), ('state', 153), (':', 149), ('year', 142)]\n",
      "\n",
      "ROMANCE (top 20): \n",
      "[(',', 3899), ('.', 3736), ('``', 1045), (\"''\", 1044), ('?', 690), ('said', 331), ('!', 316), ('--', 291), (';', 264), ('would', 247), ('could', 195), ('like', 189), ('one', 182), ('back', 128), ('thought', 106), ('little', 104), ('man', 100), ('get', 95), ('time', 94), ('old', 90)]\n",
      "\n",
      "How often 'say' up for romance: \n",
      "61\n"
     ]
    }
   ],
   "source": [
    "# We create a conditional \n",
    "cfd = nltk.ConditionalFreqDist(genre_word)\n",
    "print(cfd.conditions())\n",
    "print(cfd['news'])\n",
    "print(cfd['romance'])\n",
    "print()\n",
    "\n",
    "print(\"NEWS (top 20)): \")\n",
    "print(cfd['news'].most_common(20))\n",
    "print()\n",
    "\n",
    "print(\"ROMANCE (top 20): \")\n",
    "print(cfd['romance'].most_common(20))\n",
    "print()\n",
    "\n",
    "print(\"How often 'say' up for romance: \")\n",
    "print(cfd['romance']['say'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "41ab7064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "# Let's remove the punctuation\n",
    "\n",
    "# this is a string of characters\n",
    "print(type(string.punctuation)) \n",
    "print(string.punctuation)\n",
    "\n",
    "# tokenize the punctuation characters into list\n",
    "punct = string.punctuation + \"``--''\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8e00f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_word = [(genre, word.lower()) \n",
    "              for genre in ['news', 'romance']\n",
    "                  for word in brown.words(categories=genre)]\n",
    "\n",
    "genre_wordTemp = []\n",
    "for i in range(len(genre_word)):\n",
    "    if genre_word[i][1] not in stopwords.words('english'):\n",
    "        if genre_word[i][1] not in punct:\n",
    "            genre_wordTemp.append((genre_word[i][0], stemmer.lemmatize(genre_word[i][1])))\n",
    "\n",
    "genre_word = genre_wordTemp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ada54df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "80536\n"
     ]
    }
   ],
   "source": [
    "print(type(genre_word))\n",
    "# Punctuation is removed\n",
    "print(len(genre_word)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f75880e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['news', 'romance']\n",
      "<FreqDist with 11739 samples and 51777 outcomes>\n",
      "<FreqDist with 7148 samples and 28759 outcomes>\n",
      "\n",
      "NEWS (top 20)): \n",
      "[('said', 406), ('mrs.', 253), ('would', 246), ('year', 244), ('new', 241), ('one', 221), ('state', 213), ('last', 177), ('two', 174), ('mr.', 170), ('first', 158), ('president', 143), ('home', 141), ('also', 129), ('school', 125), ('time', 123), ('week', 120), ('day', 116), ('member', 109), ('made', 107)]\n",
      "\n",
      "ROMANCE (top 20): \n",
      "[('said', 331), ('would', 247), ('could', 195), ('one', 192), ('like', 192), ('back', 128), ('thought', 109), ('time', 108), ('little', 104), ('man', 100), ('get', 99), ('day', 96), ('know', 91), ('old', 90), ('got', 90), ('way', 88), ('eye', 88), ('never', 87), ('go', 87), ('even', 86)]\n",
      "\n",
      "How often 'say' up for romance: \n",
      "68\n"
     ]
    }
   ],
   "source": [
    "# Let's see if the punctuation is here now\n",
    "cfd = nltk.ConditionalFreqDist(genre_word)\n",
    "print(cfd.conditions())\n",
    "print(cfd['news'])\n",
    "print(cfd['romance'])\n",
    "print()\n",
    "\n",
    "print(\"NEWS (top 20)): \")\n",
    "print(cfd['news'].most_common(20))\n",
    "print()\n",
    "\n",
    "print(\"ROMANCE (top 20): \")\n",
    "print(cfd['romance'].most_common(20))\n",
    "print()\n",
    "\n",
    "print(\"How often 'say' up for romance: \")\n",
    "print(cfd['romance']['say'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a8545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
